\documentclass[12pt]{article}

\usepackage{fontspec}
\usepackage{geometry}
\usepackage{lastpage}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

\makeatletter
\newcommand{\distas}[1]{\mathbin{\overset{#1}{\kern\z@\sim}}}%

\geometry{top=1in, bottom=1in, left=1in, right=1in, marginparsep=4pt, marginparwidth=1in}

\renewcommand{\headrulewidth}{0pt}
\pagestyle{fancyplain}
\fancyhf{}
\cfoot{\thepage\ of \pageref{LastPage}}

\setlength{\parindent}{0pt}
\setlength{\parskip}{12pt}

\usepackage{marginnote} % For margin years
\newcommand{\years}[1]{\marginnote{\scriptsize #1}} % New command for including margin years
\renewcommand*{\raggedleftmarginnote}{}
\setlength{\marginparsep}{-16pt} % Slightly increase the distance of the margin years from the content
\reversemarginpar

\setromanfont [Ligatures={Common}, Numbers={OldStyle}, Variant=01,
 BoldFont={LinLibertine_RB.otf},
 ItalicFont={LinLibertine_RI.otf},
 BoldItalicFont={LinLibertine_RBI.otf}
 ]{LinLibertine_R.otf}
%\setromanfont [Ligatures={Common}, Numbers={OldStyle}]{Hoefler Text}

%\usepackage[xetex, bookmarks, pdftitle={Taylor Arnold CV},pdfauthor={Taylor Arnold}]{hyperref}
%\hypersetup{linkcolor=blue,citecolor=blue,filecolor=black,urlcolor=MidnightBlue}

\usepackage{xunicode} % Allows generation of unicode characters from accented glyphs
\defaultfontfeatures{Mapping=tex-text}

\begin{document}

\begin{center}
{\bf Problem Set 03} \\
Linear Models -- Fall 2015 \\
Due date: 2015-10-07
\end{center}

\medskip

Problems sets are due at the start of class on the due date. Please hand write
or type up and print the solutions; we will not accept e-mail solution sets except
in exceptional circumstances. You may discuss problem sets with others, but must
write up your own solutions. This means that you should have no need to look at other's
final written solutions. Many of these problems come from a variety of textbooks,
which are referenced in the problems. These are for citation purposes and not because
you will need to consult the text itself (though you may feel free to do so).

\medskip

{\bf I.} General linear model

Consider the case where the spherical errors assumption is violated, and
the variance of $\epsilon$ is instead given by:
\begin{align}
\mathbb{E} (\epsilon \epsilon^t | X) &= \sigma^2 V(X) \label{gerr}
\end{align}
For some matrix $V(X)$. We decompose the variance into $\sigma^2$ and $V(x)$ because
in what follows we assume that $V(x)$ is known beforehand but $\sigma^2$ is estimated
from the data. Using the Cholesky decomposition of (Note: an earlier version of the
notes incorrectly stated that this was the decomposition of $V(x)$ rather than $V(x)^{-1}$)
$V^{-1}$, where $V^{-1} = C^t C$, consider
the transformed variants of $X$, $\epsilon$ and $y$:
\begin{align}
\tilde{y} &= Cy \\
\tilde{X} &= Cx \\
\tilde{\epsilon} &= C\epsilon
\end{align}
It is known (see Fumio Hayashi, section 1.6) that the transformed model
$\tilde{y} = \tilde{X}\beta + \tilde{\epsilon}$ follows all of the standard
linear model assumptions if the original follows all but the spherical errors
assumption. Transforming the model back into the original space yields the
generalized least squares estimator:
\begin{align}
\widehat{\beta}_{GLS} &= (X^t V^{-1} X)^{-1} X^t V^{-1} y
\end{align}

{\bf 1.} Using the transformed model, derive formulae in terms of $X$, $y$, $V$, and
$s^2$ for the confidence and prediction intervals in the general linear model.

{\bf 2.} Download the cleaned 2007 ASA flight data
(\url{euler.stat.yale.edu/~tba3/stat612/psets/pset03/data/airline2007_pset03.Rds}).
I have selected flights arriving at the top 25 airports. The dataset is
also divided into three random, evenly sized groups: I, II, and III.
Assume that $V(X)$ is a diagonal matrix that depends only on the arrival airport.

Estimate the form of $V(X)$ using the data from group I and fit the following linear
model to the data in group II using both ordinary least squares and the generalized
model suggested by your estimate of $V(X)$ (Hint: $V(X)$ is likely too large to
construct directly on your machine; either use sparse matricies or do the
matrix multiplication manually):
\begin{align}
\text{arrDelay}_i &= \text{dest}_i + \text{depDelay}_i + \epsilon_i \label{airlineMod}
\end{align}
Use constrast sums for the arrival airport (i.e., no intercept) term. How different
are the estimators $\widehat{\beta}_{OLS}$ and $\widehat{\beta}_{GLS}$?

Now, on group III construct two-sided, 95\%-prediction intervals for the arrival
delays using both estimates of $\beta$. Calculate the error rate (proportion of
observations outside of the prediction inveral) by airport. How much do
these differ between the two estimators?

{\bf 3.} Take all of the flights that arrived at ORD (Chicago O'hare) airport on
2007-01-11, and order the data from the earliest arrival to the latest arrival.
Fit the following linear model on the data and plot a time series of the residuals.
\begin{align}
\text{arrDelay}_i &= \beta_0 + \beta_1\cdot\text{depDelay}_i + \epsilon_i
\end{align}
What assumptions of the classical regression does your plot suggest are
violated in this model?

A common description of this type of model is that the covariance of the errors
follows the following:
\begin{align}
\mathbb{E}(\epsilon_i \epsilon_j) &= \sigma^2 \cdot e^{- \phi |i - j|}
\end{align}
Using the estimate of $\sigma^2$ from the original regression model, derive
a reasonable estimate of $\phi$ from the model output (Hint: look at the case
where $|i-j|$ is equal to $1$ and find the $\phi$ that yields the
sample covariance).

Now, using the predicted $\phi$, fit the ordinary least squares and generalized
least squares model from arrivals to ORD (Chicago O'hare) airport on 2007-02-13.
How much do the two estimated $\widehat{\beta}$ differ from one another? Now find the
predicted values $\widehat{y}$ for the two estimates of $\beta$. How much do
these differ? Which is a better fit of the data?

\newpage

{\bf II.} Breaking classical linear model assumptions

In these problems, we ask you to run simulations in R to estimate the effect of
violating various assumptions in the classical multivariate linear model presented
in class. {\it For these problems, please attatch your R code as well as the written
solutions}.

{\bf 1. Normality} Construct a linear model with $p=5$, $n=1000$,
$X$ generated by independent random normals, and $\beta = (1,1,1,0,0)$.
For the following error distributions, generate an independent noise
vector $\epsilon$ and set $y = X\beta + \epsilon$ (with no intercept):
\begin{enumerate}
\item normal distribution with $\sigma = 1$, \texttt{rnorm}
\item continuous uniform distribution from $-2$ to $2$, \texttt{runif}
\item t-distribution with $2$ degrees of freedom, \texttt{rt}
\item discrete uniform over the set $\{-1,1\}$, \texttt{sample}
\item standard Cauchy distribution, \texttt{rcauchy}
\end{enumerate}
For each, calculate the probability that the standard,
two-sided, 95\%-confidence interval (which assumes normality) for $\beta_1$
covers the true $\beta_1$ by iterating the simulation (about $20000$ times
each should be enough). Use a fixed $X$ matrix over the iterations.
How do you feel about the importance of the normality assumption given this simulation?

{\bf 2. Spherical errors} Consider the following model for the error terms
(setting $\epsilon_0 = 0$ for the base case) for some $\phi > 0$:
\begin{align}
\delta_t &\sim_{i.i.d.} \mathcal{N}(0,1), \quad t=1,\ldots,n \\
\epsilon_t &= \phi \cdot \epsilon_{t-1} + \delta_t
\end{align}
Write out the variance-covariance matrix of $\epsilon$ for $n=3$.

Now, again consider a linear model with $p=5$, $n=1000$,
$X$ generated by independent random normals, and $\beta = (1,1,1,0,0)$ using
the constructed $\epsilon$. For $\phi$ equal to $0.5$, $0.9$, and $1$ run
a simulation to determine the probability that the confidence
interval for $\beta_1$ falls within the standard,
two-sided, 95\%-confidence interval (which assumes normality) for $\beta_1$.
(You may need a double loop for this, so we only need 2500 iterations here).
How do you interpret these results?

{\bf 3. Endogeneity} Finally, consider the autoregression model (we
intialize $Y_0 = 0$):
\begin{align}
Y_t &= \beta Y_{t-1} + \epsilon_t
\end{align}
Where $\epsilon$ is a random variable with a standard multivariate normal
distribution. Why does this model violate strict endogeneity?

Run a simulation with $n=1000$ and $\beta$ equal to $0.5$, $0.9$, and $1$.
Determine the expected bias of the ordinary least squares estimator
(with no intercept) for $\beta$ in each of these cases.
How do you interpret these results?

\end{document}





