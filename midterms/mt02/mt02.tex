\documentclass[12pt]{article}

\usepackage{fontspec}
\usepackage{geometry}
\usepackage{lastpage}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

\geometry{top=1in, bottom=1in, left=1in, right=1in, marginparsep=4pt, marginparwidth=1in}

\renewcommand{\headrulewidth}{0pt}
\pagestyle{fancyplain}
\fancyhf{}
\cfoot{\thepage\ of \pageref{LastPage}}

\setlength{\parindent}{0pt}
\setlength{\parskip}{12pt}

\usepackage{marginnote} % For margin years
\newcommand{\years}[1]{\marginnote{\scriptsize #1}} % New command for including margin years
\renewcommand*{\raggedleftmarginnote}{}
\setlength{\marginparsep}{-16pt} % Slightly increase the distance of the margin years from the content
\reversemarginpar

\setromanfont [Ligatures={Common}, Numbers={OldStyle}, Variant=01,
 BoldFont={LinLibertine_RB.otf},
 ItalicFont={LinLibertine_RI.otf},
 BoldItalicFont={LinLibertine_RBI.otf}
 ]{LinLibertine_R.otf}
%\setromanfont [Ligatures={Common}, Numbers={OldStyle}]{Hoefler Text}

%\usepackage[xetex, bookmarks, pdftitle={Taylor Arnold CV},pdfauthor={Taylor Arnold}]{hyperref}
%\hypersetup{linkcolor=blue,citecolor=blue,filecolor=black,urlcolor=MidnightBlue}

\usepackage{xunicode} % Allows generation of unicode characters from accented glyphs
\defaultfontfeatures{Mapping=tex-text}

\begin{document}

\begin{center}
{\bf Midterm 02} \\
Linear Models -- Fall 2015 \\
Due: 2015-12-07
\end{center}

\medskip

This assignment should be treated similarly to a problem set, with the one
caveat that you must work on it by yourself without collaborating with other
students. You are welcome to ask Jason on I for help on understanding the
questions but we will not help with the content of the questions. You are allowed
to access whatever notes or texts you would like.

{\bf 1. (25 points)} Consider a $3$-by-$4$ matrix $X$ and the
regression vector $\beta$ equal to $(1, 1, 1)^t$. Define $y$ as the following (i.e., no
error terms of offsets):
\begin{align*}
y = X \beta.
\end{align*}
Construct $X$ such that that solving the least squares
problem (that is, without a noise term, the same way I did in class) by inverting
the matrix $X^t X$ fails to reconstruct the correct $\beta$ but using the pseudoinverse
and QR trick both do. Then repeat this with an example for which all of these methods fail.
Full credit for any working solution, bonus points if the matrix $X$ looks
`reasonable' at first glance. For each of the two cases case print out the matrix and show
the three error rates (direct solve, QR of $X$, and pseudoinverse of $X$). Hint: the inverse
condition number need to be between \texttt{sqrt(.Machine\$double.eps)} and
\texttt{.Machine\$double.eps} for the first matrix, and less than both in the second.

% {\bf 2. (10 points)} Construct a simulated dataset $X$ and response vector $y$ such
% that the lasso solution path \textit{returns} a vector from the active set back into
% the inactive set. That is, there exists a $j$ such that $\widehat{\beta}_j^{\lambda_1}$ is non-zero
% but $\widehat{\beta}_j^{\lambda_2}$ for some $\lambda_2 < \lambda_1$. Do not give me the
% data, but rather supply R code which generates such a dataset. For full credit, explain
% why you would expect your simulated model to behave like this. Note: Do not just simulate
% a large set of data until this happens! Hint: You will want to use the \textbf{lars} package
% rather than \textbf{glmnet} for this.

{\bf 2. (75 points)} This question concerns a dataset constructed from a corpus of texts.
I have supplied a term frequency matrix (which gives the words counts for any word contained
in at least $3$ documents), and a set of two classification vectors. These indicate whether
the author was older than $22$ years of age, and whether the author self-identified as
female. The data are contained here (you will need to load the Matrix package as the
data matrix is stored in a sparse format):
\begin{quote}
\url{http://www.stat.yale.edu/~tba3/class_data/metaData.Rds}\\
\url{http://www.stat.yale.edu/~tba3/class_data/mmLemma.Rds}\\
\url{http://www.stat.yale.edu/~tba3/class_data/lset.Rds}
\end{quote}
The rows of the meta data and data matrix line up together. The data \textit{lset} gives the word
corresponding to each column of the data matrix. Notice that approximately one third of the
responses are set to \texttt{NA}. Your task is
to fill in the missing predictions for both of these responses. You will need to supply
a csv file formated like the following (spacing is not important):
\begin{quote}
id,      female, age\\
0001,      1, 1\\
0002,      1, 0\\
0003,      1, 1\\
0004,      0, 1
\end{quote}
This should be done for all of the samples, not just the missing ones! Notice that you need
discrete predictions $0$ or $1$, not probabilities. Your goal is to minimize the raw
prediction errors.

To answer this question, upload your predictions as a plain text csv file to the classesV2
site and write a short 1-1.5 page response describing how you approached this problem and how
well you believe your prediction will do on the unknown data. This should contain absolutely
no code, and be entirely in prose. You may include tables or figures, but the total response
should be no longer than two standard sized pages long.
Full credit will be given for any reasonably predictive model and approach; bonus points for
particularly clever ideas and top performing estimates.


\end{document}





